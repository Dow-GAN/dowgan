{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7554b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6e8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data = pd.read_csv('DataImpurityGAN.csv')\n",
    "# Drop First Column\n",
    "data = data.drop(columns='Primary ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b293d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NAN\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7be6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c39dcdf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89db3221",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for column in df:\n",
    "    fig = go.Figure(data=go.Scatter(x=df.index, y=df[column], mode='markers'))\n",
    "    fig.update_layout(\n",
    "        title=column,\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=\"Value\",\n",
    "        autosize=False,\n",
    "        width=1000,\n",
    "        height=500,\n",
    "        margin=dict(\n",
    "            l=50,\n",
    "            r=50,\n",
    "            b=100,\n",
    "            t=100,\n",
    "            pad=4\n",
    "        ),\n",
    "        paper_bgcolor=\"LightSteelBlue\",\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea1ca1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in df:\n",
    "    plt.figure(figsize=(10, 6))  # Increase the figure size\n",
    "    plt.scatter(df.index, df[column], s=10)  # Decrease point size by setting s=10\n",
    "    plt.title(column)  # Set title to be the column name\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf28da3",
   "metadata": {},
   "source": [
    "# Here we split the two classes into different dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd89bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by the \"Class\" column\n",
    "grouped_data = data.groupby('Class')\n",
    "\n",
    "# Create an empty dictionary to store the DataFrames\n",
    "dfs = {}\n",
    "\n",
    "# Iterate over each group and store the data in the dictionary\n",
    "for class_, group in grouped_data:\n",
    "    dfs[class_] = group.copy()\n",
    "\n",
    "# Access the separate DataFrames\n",
    "df_class_1 = dfs[1]\n",
    "df_class_2 = dfs[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2554e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have two different dataframes we can drop class column\n",
    "df_class_1 = df_class_1.drop(columns= 'Class')\n",
    "df_class_2 = df_class_2.drop(columns= 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1.shape, df_class_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15c1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Names saved for later when we remake DataFrames\n",
    "column_names = df_class_2.columns\n",
    "# column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8c6ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we Scale the data\n",
    "# Create an instance of StandardScaler\n",
    "scaler1 = StandardScaler()\n",
    "scaler2 = StandardScaler()\n",
    "\n",
    "# Fit the scaler to data\n",
    "scaler1.fit(df_class_2)\n",
    "scaler2.fit(df_class_2)\n",
    "\n",
    "# Transform the data to Standard scale\n",
    "target_1 = scaler1.transform(df_class_1)\n",
    "target_2 = scaler2.transform(df_class_2)\n",
    "target_2.shape, target_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafff019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify length of training data first we train the class 2 since it has more data\n",
    "num_data = 5000\n",
    "target_1 = pd.DataFrame(target_2, columns = column_names).iloc[:(num_data-3000)]\n",
    "target_2 = pd.DataFrame(target_2, columns = column_names).iloc[:num_data]\n",
    "target_2.shape, target_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b7bdc",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9879e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input size and output size specify the shape of the tensor fed into the NN\n",
    "# input and output correspond to the number of features\n",
    "input_size = len(df_class_2.columns) \n",
    "output_size= len(df_class_2.columns)\n",
    "# The size of the hidden layers within the transformer. This is also the size of the output from the embedding layer\n",
    "# must be even number\n",
    "# hidden_size = len(df_class_2.columns)+1\n",
    "hidden_size = 128\n",
    "# length of the input sequence, which is the number of historical data points that will be used to predict futere timesteps\n",
    "seq_length = 10 \n",
    "# sequence of future data that the model should try to predict\n",
    "output_steps = 10\n",
    "# Number of layers in the transformer to stack\n",
    "num_layers = 5\n",
    "# Number of heads in the multi-head attention mechanism of the transformer ( hidden_size must be divisible by num_heads)\n",
    "num_heads = 8\n",
    "# The dropout rate, a regularization technique\n",
    "dropout = 0.1\n",
    "# batch size is the size of data used in training\n",
    "batch_size = 32\n",
    "# Learning Rate\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdfa508",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, seq_length, output_steps):\n",
    "        # Transform data to tensors\n",
    "        self.data = torch.tensor(data.values, dtype=torch.float32)\n",
    "        # Past time steps\n",
    "        self.seq_length = seq_length\n",
    "        # Future time steps\n",
    "        self.output_steps = output_steps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_length - self.output_steps + 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Returns two tensors one for historical data and the other for future data to predict\n",
    "        return (self.data[index:index+self.seq_length],\n",
    "                self.data[index+self.seq_length:index+self.seq_length+self.output_steps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8351b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the dataset and dataloader\n",
    "dataset = TimeSeriesDataset(target_2, seq_length, output_steps)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_layers, hidden_size, num_heads, dropout, seq_length, n_output_steps):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.seq_length = seq_length\n",
    "        self.n_output_steps = n_output_steps\n",
    "\n",
    "        self.embedding = nn.Linear(input_size, hidden_size)\n",
    "        self.pos_encoder = PositionalEncoding(hidden_size, dropout)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(hidden_size, num_heads, hidden_size, dropout)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_range = 0.1\n",
    "        self.embedding.weight.data.uniform_(-init_range, init_range)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-init_range, init_range)\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size = input.size(0)\n",
    "        input = self.embedding(input)  # Embedding\n",
    "        input = self.pos_encoder(input)  # Positional encoding\n",
    "        output = self.encoder(input)  # Encoding\n",
    "        output = self.decoder(output)  # Linear layer\n",
    "        return output\n",
    "    \n",
    "# Define the positional encoding module Allows the transformer to know the unique position of the data\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        # Here we make a matrix of the input data with each having a unique position\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449506fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = Transformer(input_size, output_size, num_layers, hidden_size, num_heads, dropout, seq_length, output_steps)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8160c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 200  # Change this if necessary\n",
    "model.train()  # Set the model to training mode\n",
    "\n",
    "# Initialize a list to hold the losses\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs = inputs\n",
    "        targets = targets\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Add the loss to the list\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    if (epoch) % 10 == 0:  # Print loss every 100 batches\n",
    "        print (f'Epoch [{epoch}/{num_epochs}],  Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3203240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(losses)\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7b4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a76bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model, data, seq_length, output_steps):\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Make sure data is a torch Tensor\n",
    "    if not isinstance(data, torch.Tensor):\n",
    "        data = torch.Tensor(data)\n",
    "        \n",
    "    # Number of forecasts\n",
    "    num_forecasts = len(data) - seq_length\n",
    "    \n",
    "    # Container for predictions\n",
    "    predictions = torch.zeros(num_forecasts, output_steps, data.shape[-1])\n",
    "    \n",
    "    # Slide over the time-series data\n",
    "    for i in range(num_forecasts):\n",
    "        # Get a sequence of data\n",
    "        seq = data[i:i+seq_length]\n",
    "        \n",
    "        # Add an extra dimension for batch\n",
    "        seq = seq.unsqueeze(0)\n",
    "        \n",
    "        # Compute the output\n",
    "        with torch.no_grad():\n",
    "            out = model(seq)\n",
    "        \n",
    "        # Save only the outputs for the last time step\n",
    "        predictions[i] = out[0]\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77fc05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is data used for predicting the next sequence\n",
    "pred_data = pd.DataFrame(target_2, columns = column_names).iloc[3000:num_data]\n",
    "pred_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c503fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.tensor(pred_data.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aec3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = forecast(model, input_data, seq_length, output_steps)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5723cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b41491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse scale the prediciton\n",
    "predictions = scaler2.inverse_transform(predictions[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217594cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame(df_class_2, columns = column_names).iloc[num_data:]\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3ea4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array_np = test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267d484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56f280c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate over each feature\n",
    "for i in range(44):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot the predicted data\n",
    "    plt.plot(predictions[:, i], label='Predictions')\n",
    "    \n",
    "    # Plot the actual test data\n",
    "    plt.plot(test_array_np[:, i], label='Actual')\n",
    "\n",
    "    \n",
    "    plt.title(f'{column_names[i]}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33192f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pandas DataFrame to numpy array\n",
    "test_array_np = test_data.values\n",
    "\n",
    "# Run PCA on test data and predictions\n",
    "pca = PCA(n_components=2)\n",
    "test_pca = pca.fit_transform(test_array_np)\n",
    "predictions_pca = pca.transform(predictions)\n",
    "\n",
    "# Plot test data\n",
    "plt.scatter(test_pca[:, 0], test_pca[:, 1], label='Test data')\n",
    "\n",
    "# Plot prediction data\n",
    "plt.scatter(predictions_pca[:, 0], predictions_pca[:, 1], label='Predictions')\n",
    "plt.title('Class 2 PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832531f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pandas DataFrame to numpy array\n",
    "test_array_np = test_data.values\n",
    "\n",
    "# Run t-SNE on test data and predictions\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "test_tsne = tsne.fit_transform(test_array_np)\n",
    "predictions_tsne = tsne.fit_transform(predictions)\n",
    "\n",
    "# Plot test data\n",
    "plt.scatter(test_tsne[:, 0], test_tsne[:, 1], label='Test data')\n",
    "\n",
    "# Plot prediction data\n",
    "plt.scatter(predictions_tsne[:, 0], predictions_tsne[:, 1], label='Predictions')\n",
    "plt.title('Class 2 tSNE')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc93732",
   "metadata": {},
   "source": [
    "# Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64909705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the dataset and dataloader\n",
    "dataset = TimeSeriesDataset(target_1, seq_length, output_steps)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b211a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = Transformer(input_size, output_size, num_layers, hidden_size, num_heads, dropout, seq_length, output_steps)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff839739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 200  # Change this if necessary\n",
    "model.train()  # Set the model to training mode\n",
    "\n",
    "# Initialize a list to hold the losses\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs = inputs\n",
    "        targets = targets\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Add the loss to the list\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    if (epoch) % 10 == 0:  \n",
    "        print (f'Epoch [{epoch}/{num_epochs}],  Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbac36c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3394660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is data used for predicting the next sequence\n",
    "pred_data_1 = pd.DataFrame(target_1, columns = column_names).iloc[1300:2000]\n",
    "pred_data_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2353d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1 = pd.DataFrame(df_class_1, columns = column_names).iloc[2000::]\n",
    "test_data_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31e98d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_1 = torch.tensor(pred_data_1.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8ea40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_1 = forecast(model, input_data_1, seq_length, output_steps)\n",
    "predictions_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_1 = scaler1.inverse_transform(predictions_1[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34ca1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array_np_1 = test_data_1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ac700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate over each feature\n",
    "for i in range(44):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot the predicted data\n",
    "    plt.plot(predictions_1[:, i], label='Predictions')\n",
    "    \n",
    "    # Plot the actual test data\n",
    "    plt.plot(test_array_np_1[:, i], label='Actual')\n",
    "\n",
    "    \n",
    "    plt.title(f'{column_names[i]}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c951f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA on test data and predictions\n",
    "pca = PCA(n_components=2)\n",
    "test_pca = pca.fit_transform(test_array_np_1)\n",
    "predictions_pca = pca.transform(predictions_1)\n",
    "\n",
    "# Plot test data\n",
    "plt.scatter(test_pca[:, 0], test_pca[:, 1], label='Test data')\n",
    "\n",
    "# Plot prediction data\n",
    "plt.scatter(predictions_pca[:, 0], predictions_pca[:, 1], label='Predictions')\n",
    "plt.title('Class 1 PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bd90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run t-SNE on test data and predictions\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "test_tsne = tsne.fit_transform(test_array_np_1)\n",
    "predictions_tsne = tsne.fit_transform(predictions_1)\n",
    "\n",
    "# Plot test data\n",
    "plt.scatter(test_tsne[:, 0], test_tsne[:, 1], label='Test data')\n",
    "\n",
    "# Plot prediction data\n",
    "plt.scatter(predictions_tsne[:, 0], predictions_tsne[:, 1], label='Predictions')\n",
    "plt.title('Class 1 tSNE')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9949c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the generated data\n",
    "generated_predictions = np.concatenate((predictions, predictions_1), axis=0)\n",
    "generated_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate Test Data\n",
    "test_contcatenate = np.concatenate((test_array_np, test_array_np_1), axis=0)\n",
    "test_contcatenate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e5711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA on test data and predictions\n",
    "pca = PCA(n_components=2)\n",
    "test_pca = pca.fit_transform(test_contcatenate)\n",
    "predictions_pca = pca.transform(generated_predictions)\n",
    "\n",
    "# Plot test data\n",
    "plt.scatter(test_pca[:, 0], test_pca[:, 1], label='Test data')\n",
    "\n",
    "# Plot prediction data\n",
    "plt.scatter(predictions_pca[:, 0], predictions_pca[:, 1], label='Predictions')\n",
    "plt.title('Overall PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run t-SNE on test data and predictions\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "test_tsne = tsne.fit_transform(test_contcatenate)\n",
    "predictions_tsne = tsne.fit_transform(generated_predictions)\n",
    "\n",
    "# Plot test data\n",
    "plt.scatter(test_tsne[:, 0], test_tsne[:, 1], label='Test data')\n",
    "\n",
    "# Plot prediction data\n",
    "plt.scatter(predictions_tsne[:, 0], predictions_tsne[:, 1], label='Predictions')\n",
    "plt.title('Overall tSNE')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
